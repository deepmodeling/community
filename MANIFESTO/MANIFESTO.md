# The DeepModeling Manifesto

The integration of machine learning and physical modeling is changing the paradigm of scientific research. Those who hope to extend the frontier of science and solve challenging practical problems through computational modeling are coming together in new ways never seen before. This calls for a new infrastructure--new platforms for collaboration, new coding frameworks, new data processing schemes, and new ways of using the computing power.  It also calls for a new culture—the culture of working together closely for the benefit of all, of free exchange and sharing of knowledge and tools, of respect and appreciation of each other's work, and of the pursuit of harmony among diversity.

The DeepModeling community is a community of such a group of people.

## What is DeepModeling?
The two most important applications of computing are machine learning and physical modeling. The former is an effective tool for analyzing complex data; the latter is a scientific description of the physical world. The vitality boosted by the effective integration of the two is driving scientific research toward a more platform-oriented paradigm. DeepModeling will ultimately become a comprehensive methodology and a suite of open-source tools that embody the deep integration of literature and data, computing power and computation, experimentation, and modeling.People who are attracted by the DeepModeling community are attracted by its open, inclusive environment, as well as its dedication to the cause of advancing scientific progress worldwide.

## Why choose open source?

There are different interpretations of the term "open source". The consensus among the DeepModeling community is that open source is a collaborative software development platform based on the spirit of openness and sharing. Open source is a familiar concept for people in the fields of machine learning and computer science, but it is not yet popular  across many scientific disciplines. What we advocate is that an algorithm or software should not be judged by the reputation of the journal in which it is published, but by its ability to solve real world problems and its actual contribution to science. The sustainable development of a software requires continuous investment in manpower. It should undergo incremental improvement, and it should be put to the test of solving real-world problems in an open environment. This is often difficult to achieve by individuals or individual groups. The open-source community provides better solutions.

## The history of the DeepModeling community 

**`2017.12.12-2021.5.6`**: 

The "DeepModeling Community" started with the initiation of the "deepmd-kit" project. “deepmd-kit" is a software tool that combines machine learning and molecular dynamics, which helps to overcome a long-standing difficulty in the field of molecular dynamics, namely the dilemma of having to choose between efficiency and accuracy. The name "DeepModeling" was proposed by early developers of the deepmd-kit project, with the intention of using deep learning tools to solve the curse of dimensionality problem in multi-scale modeling. DeepModeling has therefore become the name of the GitHub organization (https://github.com/deepmodeling) which manages the original deepmd-kit project. After the development of deepmd-kit, the DeepModeling community has successively initiated projects such as dpdata, dp-gen, and dpdispatcher, and extended the modeling scale to electronic structure level through projects such as deepks-kit and ABACUS. These projects have brought together people from all over the world working on molecular simulations. 

**`2021.5.6-2025.5.6`**: 

As the DeepModeling community continues to gain recognition, more and more developers and projects are joining its ranks. Currently, the community hosts over 30 open-source projects, spanning a wide range of scales and scientific problems. These include, for example, density functional theory (such as [ABACUS](https://github.com/deepmodeling/abacus-develop), [DeePKS](https://github.com/deepmodeling/deepks-kit), [LIBRI](https://github.com/deepmodeling/LibRI), [DeePTB](https://github.com/deepmodeling/DeePTB)), molecular dynamics (such as [DeePMD-kit](https://github.com/deepmodeling/deepmd-kit), [DMFF](https://github.com/deepmodeling/DMFF), DeePCG), and combustion fluid dynamics (such as [DeepFlame](https://github.com/deepmodeling/deepflame-dev)). The community has also developed [dflow](https://github.com/deepmodeling/dflow), a workflow framework for AI for Science, along with a series of domain-specific workflows built on top of it, such as [APEX](https://github.com/deepmodeling/APEX). In recent years, the community has launched the [OpenLAM Initiative](https://www.aissquare.com/openlam) for large atomistic models, and has successively released models such as DPA1 and DPA2. Alongside the growth of its project ecosystem, DeepModeling has continued to enhance its community infrastructure and governance, and has introduced a range of community activities—including the Colombo Academy—to support learning and participation.To date, DeepModeling has attracted tens of thousands of users from more than 20 countries around the world.

## The short-term plan and long-term vision of the DeepModeling community

**`2021.5.6`**:

In the short term, developers in the DeepModeling community will focus on  atomic-scale simulation methods and tools. This includes solving the many-body Schrödinger equation, electronic structure calculation, molecular dynamics simulation, and coarse-grained molecular dynamics simulation. This also includes tasks such as data generation, model training, high-performance optimization, etc. In addition, it includes different workflows and management tools, as well as computing power scheduling tools for different systems, different scenarios, and different purposes. 

It should be pointed out that the combination of physical modeling and machine learning often fundamentally changes the implementation logic of a piece of software. Therefore, the new infrastructure will not be settled once and for all, but will be gradually improved through an iterative process and  upgrades from time to time.

In the long run, the DeepModeling community is committed to combining physical models at all scales with machine learning methods, using the most cutting-edge computing platforms to solve the most challenging scientific and technological problems faced by the human society.

**`2025.5.6`**:

While continuing to advance solutions that integrate machine learning with multi-scale physical modeling, the DeepModeling community will, in the short term, expand its exploration into areas such as “AI for literature analysis” and “AI for experimental science.” In the long run, the DeepModeling community is committed to promoting the development of scientific general intelligence and to tackling the most challenging scientific and technological problems facing human society.


## How can you contribute?

If you are focused on machine learning algorithm research or skilled in deploying AI models into real-world systems, the DeepModeling community offers a wealth of innovative, research-driven scenarios that directly address scientific bottlenecks. At the data engineering level, you can build automated systems for mining knowledge from scientific literature, develop cross-modal data integration tools, construct automated pipelines that connect experimental and computational data, and generate high-quality, AI-ready datasets. At the agent development level, you can design intelligent experimental assistants, enable closed-loop control of experimental workflows, and build collaborative platforms for multi-agent systems to accelerate the validation of scientific hypotheses. These contributions will redefine the efficiency and scope of scientific discovery—turning every intelligent agent into a pioneer of paradigm shifts in research, and every line of code into part of the next-generation research infrastructure for deep human–machine collaboration.

If you have long been engaged in experimental work, the DeepModeling community urgently needs your hands-on expertise to drive the intelligent upgrade of laboratory instrumentation. From documenting and promoting standardized experimental procedures, to designing intelligent experimental assistants; from establishing unified control protocols across instruments, to parsing experimental data and further enabling rapid, closed-loop iteration between experiments and AI models—your deep understanding of the pain points in experimental processes will play a vital role in improving research efficiency and will serve as a driving force at the core of experimental intelligence transformation.

If you are a programmer who loves science and    are inspired by the vision of the DeepModeling community, you can contribute not only through new algorithms, but also code development specifications, document writing specifications, community databases, task scheduling, workflow management and other tools.  In addition, you can contribute to code architecture design and high-performance optimization tasks in the DeepModeling community. People who conduct scientific research using these tools will greatly appreciate your expertise and contribution. 

If you are a hardcore developer familiar with topics such as electronic structure calculations, molecular dynamics, and finite element methods, the DeepModeling community will be your place to showcase your talents. The addition of machine learning components requires us to rethink about architecture design, each specific implementation for the tasks mentioned above and high-performance optimization. You will become important bridges that connect other developers, contributors, and users in different areas.

If you have only used some basic scientific software and have worked on some post-processing scripts, the DeepModeling community also needs you. Try to ask questions and communicate on github/gitee and other communication platforms, try to give opinions, and try to fork, commit, pr... Your little by little contribution will make the DeepModeling community better and better, and the DeepModeling community will be very grateful for such contributions.

Even if you are just a bystander, if you support the concept of the DeepModeling community, your recognition and dissemination will also be a great encouragement and support for the DeepModeling community.

## Final remarks

Despite the tremendous advances in AI and computing power, the scientific research community is largely embedded in an old-fashioned culture. Many of the most important tasks rely on legacy codes. The core algorithms used in many commercial software have been outdated. The self-sufficient style of work is similar to that of the agricultural ages resulting in poor efficiency. 

The DeepModeling project promises to change all that. 

The combination of machine learning and physical modeling calls for a new paradigm, the open-source community paradigm. Such a paradigm has long been embraced in the computer and electronics industry, with Linux and Andriod being the very well-known examples. In this sense, what the DeepModeling project does is to borrow these ideas and use them for scientific fields. Working together as an open-source community will make our work more productive, up to date, reliable, and transparent. The spirit of close collaboration, of respect and building on each other’s work will surely inspire more and more people to join the cause of advancing science for the benefit of the human society. This is an exciting opportunity. This is the future of science!

