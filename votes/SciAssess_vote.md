# A Vote for New Projects: SciAssess

## Proposal

**SciAssess**, a benchmark specifically designed for the comprehensive evaluation of LLMs in scientific literature analysis. It aims to thoroughly assess the efficacy of LLMs by evaluating their capabilities in Memorization (L1), Comprehension (L2), and Analysis & Reasoning (L3). It encompasses a variety of tasks drawn from diverse scientific fields, including biology, chemistry, material, and medicine. 

SciAssess inclusion in the DeepModeling community aligns with the community's short-term plan of expanding exploration into “AI for literature analysis” area.

For more information, see the [original repository](https://github.com/sci-assess/SciAssess)

## Deadline

The vote will be open for at least 6 days unless there is an objection.

## Scope

TOC MEMBERS.

## Result

Approved by:

zhixchen

KuangYu

mohanchen

wanghan-iapcm

See also https://github.com/deepmodeling/community/pull/54
